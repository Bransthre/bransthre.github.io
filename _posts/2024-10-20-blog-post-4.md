---
title: '[COMPSCI 180] Project 4A: Let The Imagery Blend In'
date: 2024-10-20
permalink: /posts/cs180-proj4a/
tags:
  - COMPSCI 180
---

# COMPSCI 180 Project 4A Writeup
![Teaser Figure](/post_assets/cs180/proj4/mosaic_a.png)

## Introduction
In this (rushed) blog post, I detail my doings (and wrongdoings) in Project 4A (one of them being starting late due to all the other businesses in life).

The assignment discusses image warping and mosaicing. Image warping is a business that we have discussed using a large part of our previous post, while mosaicing is a new topic. What is mosaicing? Mosaicing is stitching two pictures of different perspectives together, forming a panorama of some two sights that have resulted from an observer staying at a fixed global coordinate, but perhaps looking at something from a different angle. An example will be quickly shown in our results section.

We have repeatedly mentioned the word "stitching", but what really is "stitching"? And how is warpping, an elemental operation for image transformation, related to our works (and my wrongdoings)? We will detail the methodological details of these efforts in the Preliminaries sections, then describe their experimental outcomes using the section following Preliminaries.

## Preliminaries
Let us consider a toy example of the two following pictures:

Picture A             |  Picture B
:-------------------------:|:-------------------------:
![](/post_assets/cs180/proj4/mosaic_c2.jpg)  |  ![](/post_assets/cs180/proj4/mosaic_c1.jpg)

These are different views of Prof. Efros' office seen from the same global coordinate (I stand at the exact same location when looking at these views), but the door's overall orientation is quite different, because the angle at which I look at the door is different. Therefore, one door is slanted towards the left, and the other is slanted towards the right! Amazing!

So how do we stitch these two pictures together? Well, there is a commonality between these two pictures that we can merge with: the door. Let's just overlap the images by where the door is... except we can't just do that. The door's shapes are different. We must transform, say, Picture B's door's shape into that of Picture A's when we overlap the images (and naturally, all other components follow the same transformation). This is where warpping comes in.

### Projective Mapping
In the last blogpost, we discussed finding an affine transformation between two triangles by finding a 3-by-3 transformation matrix via homogeneous coordinates. Here, we concern a different form of transformation: projective transformation.

$$
\begin{bmatrix}
wx' \\ wy' \\ w
\end{bmatrix} =
\begin{bmatrix}
    a & b & c \\
    d & e & f \\
    g & h & 1
\end{bmatrix}
\begin{bmatrix}
    x \\ y \\ 1
\end{bmatrix}
$$

With at least 4 pairs of $(x, y), (x', y')$ as well as the definite assumption that $gx + hy + 1 = w$, we can construct the following system of linear equations and use least squares algorithm to find the optimal estimators for projective mapping parameters:

$$
\forall (x, y, x', y') \in \mathcal{D}, 
\begin{cases}
    x' = ax + by + c - gx x' - hy x' \\
    y' = dx + ey + f - gx y' - hy y'
\end{cases}
$$

here, $\mathcal{D}$ is the set of all correspondence points, such as the corners of the door and doorknobs.

### Warp2Stitch
Upon obtaining this projection matrix, it's warping time. The general technique of warpping can be seen at the post for project 3, but I will kindly reiterate it here.

#### Forward vs. Inverse Warpping
There are two general patterns for warpping: forward-warpping and inverse-warpping.

In forward warpping, once we infer the operator $\mathcal{T}$, we map the value of each pixel at position $(x, y)$ to its transformed equivalent $\mathcal{T}((x, y))$, and non-integer pixel coordinates will have its values distributed among neighboring pixels. However, this pattern of warpping easily leads to "holes" in the resulting product, where certain pixels do not receive any coloration.

![Warpping](/post_assets/cs180/proj3/Slide8.PNG)

Therefore, our assignment proceeds with an alternative method: inverse warpping. In this paradigm, we infer an operator $\mathcal{T}$ from the source image to a target image, and use the inverse operator: $\mathcal{T}^{-1}$ to do pixel mapping as described above. However, since the source image's pixel values are all known, we can safely interpolate the unknown pixel values with its neighbors. An efficient manner of doing so is bi-linear interpolation, where for each $(x_t, y_t) = \mathcal{T}^{-1}(x, y)$ resulted, its coloring is inferred as a weighted sum of its neighbor.
In our assignment, we apply a variation of this logic that will be described below (out of the unclarity of the original assignment's instruction, we devise a variation of this interpolation function fitting our context).

### Overall Flow of Methodology
The overall flow of mosaic would then seem as follows:

1. Obtain the homography transformation via least squares to match correspondences from Picture B to Picture A
2. Transform the corners of Picture A onto Picture B, seeing where it will generally land.
3. Take a polygon mask using the transformed corners, and obtain all integer coordinates for pixels in there.
4. Inverse warp onto the transformed polygon mask mentioned in (3), and use bilinear interpolation to fill in the mask
5. Use an infinity-norm based distance transform mask to blend the two images. A Laplacian kernel would be much preferred, but I need to go revise exam logistics and write SoPs.

## Rectify and Justify
To make sure our warpping implementation is intact, we would like to try rectifying some aspects of an image, such that a specific set of four pairs of correspondence points should form a square or rectangle in a warpped image.

The results are as follows:

![rectified_a](/post_assets/cs180/proj4/rectified_a.png)

![rectified_b](/post_assets/cs180/proj4/rectified_b.png)

## Sike, it's Mosaic
Now, we can directly apply the method spoken in the Prelminiaries section, and stitch images together. I experimented on distance transformations using L2 distance instead of L-infinity, which will provide a more symmetrical mask in a radial sense. Pictures are also cropped beforehand as L-infinity masks may suffer from a large difference between picture height and width.

Original Picture A             |  Original Picture B
:-------------------------:|:-------------------------:
![](/post_assets/cs180/proj4/mosaic_a2.jpg)  |  ![](/post_assets/cs180/proj4/mosaic_a1.jpg)

Results:
![mosaic_a](/post_assets/cs180/proj4/mosaic_a.png)

Original Picture A             |  Original Picture B
:-------------------------:|:-------------------------:
![](/post_assets/cs180/proj4/mosaic_b2.jpg)  |  ![](/post_assets/cs180/proj4/mosaic_b1.jpg)

Results:
![mosaic_b](/post_assets/cs180/proj4/mosaic_b.png)

Original Picture A             |  Original Picture B
:-------------------------:|:-------------------------:
![](/post_assets/cs180/proj4/mosaic_c2.jpg)  |  ![](/post_assets/cs180/proj4/mosaic_c1.jpg)

Results:
![mosaic_c](/post_assets/cs180/proj4/mosaic_c.png)

Generally, the results match in structure. The color differences may be efficiently resolved using a Laplacian kernel, or be more careful when taking pictures.
